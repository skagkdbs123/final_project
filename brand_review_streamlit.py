import streamlit as st
import pandas as pd
import numpy as np
import re
from tqdm import tqdm

import matplotlib.pyplot as plt
import plotly.graph_objects as go
import seaborn as sns
import koreanize_matplotlib
import plotly.express as px

import koreanize_matplotlib
#%config InlineBackend.figure_format = 'retina'

from krwordrank.hangle import normalize
from krwordrank.word import KRWordRank
from kiwipiepy import Kiwi

import requests
from bs4 import BeautifulSoup


st.set_page_config(
    page_title="brand review analysis",
    page_icon="ğŸ‘—",
    layout="wide",
)

st.markdown("# ğŸ‘• ë¸Œëœë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”. ğŸ‘–")

st.sidebar.markdown("# ğŸ“Œ ë¸Œëœë“œ ì¢…ë¥˜")
st.sidebar.markdown("""
ë¼í¼ì§€ìŠ¤í† ì–´ lafudgestore            
ê¼¼íŒŒë‡¨ compagno         
ë“œë¡œìš°í• Draw fit         
ì¸ì‚¬ì¼ëŸ°ìŠ¤ insilence       
ì»¤ë²„ë‚« covernat         
íŒŒë¥´í‹°ë©˜í†  partimento         
í•„ë£¨ë¯¸ë„¤ì´íŠ¸ filluminate       
ì™€ë¦¿ì´ì¦Œ whatitisnt       
ìˆ˜ì•„ë ˆ suare        
ë‚´ì…”ë„ì§€ì˜¤ê·¸ë˜í”½ nationalgeographic           
ì˜ˆì¼ yale       
ë””ì¦ˆì´ìŠ¤ë„¤ë²„ëŒ“ thisisneverthat         
ì•„ì›ƒìŠ¤íƒ ë”© outstanding        
ë¦¬ lee      
ì–´ë°˜ë“œë ˆìŠ¤ avan         
""")

# select brand
brand_list = ['ë¸Œëœë“œ ì„ íƒ', 'ë¼í¼ì§€ìŠ¤í† ì–´', 'ê¼¼íŒŒë‡¨', 'ë“œë¡œìš°í•', 'ì¸ì‚¬ì¼ëŸ°ìŠ¤',
            'ì»¤ë²„ë‚«', 'íŒŒë¥´í‹°ë©˜í† ', 'í•„ë£¨ë¯¸ë„¤ì´íŠ¸', 'ì™€ë¦¿ì´ì¦Œ', 'ìˆ˜ì•„ë ˆ',
            'ë‚´ì…”ë„ì§€ì˜¤ê·¸ë˜í”½', 'ì˜ˆì¼', 'ë””ì¦ˆì´ìŠ¤ë„¤ë²„ëŒ“', 'ì•„ì›ƒìŠ¤íƒ ë”©', 'ë¦¬',
            'ì–´ë°˜ë“œë ˆìŠ¤']
choice = st.selectbox('ğŸ”ë³´ê³ ì í•˜ëŠ” ë¸Œëœë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.', brand_list)

select_brand = []
for num in range(len(brand_list)):
    if num == 0:
        pass
    elif choice == brand_list[num]:
        st.write(f'{brand_list[num]}ë¥¼ ì„ íƒí•˜ì…¨êµ°ìš”. â³ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.')
        select_brand.append(f'{brand_list[num]}')
    

# data load
brand_link = {
    'ë¼í¼ì§€ìŠ¤í† ì–´' : '1fr6RZGM_vd5L0IDS0XIJCcScn_QtFKYz',
    'ë“œë¡œìš°í•' : '1KoWlv8cQXI9kpmfVL1pSr6jLH1RvkXkt',
    'ì»¤ë²„ë‚«' : '1we5q5975vDb2iNrmTPfDNsCNrQxrrWTQ',
    'íŒŒë¥´í‹°ë©˜í† ' : '1D1BhygdkEvZU4uQQ1Y450zpZVHbdDiwc',
    'í•„ë£¨ë¯¸ë„¤ì´íŠ¸' : '190VQjL5F-8KPxQlYj3_8pY9Fb9JzmPIi',
    'ê¼¼íŒŒë‡¨' : '1AjkzWni2Lp1V2vzhe3-gwzjDT1ASCsA2',
    'ì¸ì‚¬ì¼ëŸ°ìŠ¤' : '12vrFmoKeJ_UHaXljvsO1l4rbvV1Tw4Dq' ,
    'ì™€ë¦¿ì´ì¦Œ' : '1C_hPRBxb0sp6bJdVV4OEmNmMWFqYILQZ' ,
    'ìˆ˜ì•„ë ˆ' : '1KZSMUTjqqGGMVOp5KiH7X_n23IcJL3wB',
    'ë‚´ì…”ë„ì§€ì˜¤ê·¸ë˜í”½' : '1gWhGfIluszy8oVO-RwZIKtxJ0RM8yMhn',
    'ì˜ˆì¼' : '1eIoxQZrDLhsCWEl1-NJ9yE3Biem3VIcG',    
    'ë””ì¦ˆì´ìŠ¤ë„¤ë²„ëŒ“' : '1ZgW4xBoXcNczxjMdw6YMKVEdjtgsUoyK',    
    'ì•„ì›ƒìŠ¤íƒ ë”©' : '1KfcwqNRRbKLgCNvgMIgZiRLaJ8Si8BJU',
    'ë¦¬' : '1fqw2TiNEDxyrkaSDIlcxQ6UUyUD38kgW',
    'ì–´ë°˜ë“œë ˆìŠ¤' : '1YmNK_XSR03fcKgnt6ZOmWkAusXteV8tT' 
}

@st.cache
def data_load(select_brand):
    data_link = 'https://drive.google.com/uc?id='+brand_link[select_brand]
    data = pd.read_csv(data_link) 
    return data

def graph(brand):
    ì‚­ì œ = brand[(brand["í‰ì "]=="60%") | (brand["í‰ì "]=="80%")].index
    brand = brand.drop(ì‚­ì œ)
    brand.loc[(brand["í‰ì "] == "100%"), "label"] = 1
    brand.loc[(brand["í‰ì "] == "20%") | (brand["í‰ì "] == "40%"), "label"] = 0
    brand = brand.drop_duplicates()
    brand = brand.reset_index(drop=True)
    brand["í‰ì "].value_counts()

    dfbrandê¸ì • = brand[brand["label"]==1]
    dfbrandê¸ì • = dfbrandê¸ì •.reset_index(drop=True)
    dfbrandë¶€ì • = brand[brand["label"]==0]
    dfbrandë¶€ì • = dfbrandë¶€ì •.reset_index(drop=True)

    dfbrandì‚¬ì´ì¦ˆ = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ì‚¬ì´ì¦ˆ')]
    branda = dfbrandì‚¬ì´ì¦ˆ.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandìƒ‰ê° = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ìƒ‰ê°')]
    brandb = dfbrandìƒ‰ê°.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandì¬ì§ˆ = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ì¬ì§ˆ')]
    brandc = dfbrandì¬ì§ˆ.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandëŠë‚Œ = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ëŠë‚Œ')]
    brandd = dfbrandëŠë‚Œ.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandë””ìì¸ = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ë””ìì¸')]
    brande = dfbrandë””ìì¸.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandí• = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ì˜¤ë²„|ë²„í•')]
    brandf = dfbrandí•.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandë‘ê»˜ = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ë‘ê»˜')]
    brandg = dfbrandë‘ê»˜.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandìƒ‰ìƒ = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ìƒ‰ìƒ')]
    brandh = dfbrandìƒ‰ìƒ.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandê°€ê²© = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ê°€ê²©')]
    brandi = dfbrandê°€ê²©.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandê¸°ì¥ = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ê¸°ì¥|ê¸¸ì´')]
    brandj = dfbrandê¸°ì¥.shape[0] / dfbrandê¸ì •.shape[0]

    dfbrandë¡œê³  = dfbrandê¸ì •[dfbrandê¸ì •['ë¦¬ë·°'].str.contains('ë¡œê³ ')]
    brandk = dfbrandë¡œê³ .shape[0] / dfbrandê¸ì •.shape[0]


    dfbrandë°°ì†¡ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ë°°ì†¡')]
    brandl = dfbrandë°°ì†¡.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandì‚¬ì´ì¦ˆ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ì‚¬ì´ì¦ˆ')]
    brandm = dfbrandì‚¬ì´ì¦ˆ.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandì„¸íƒ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ì„¸íƒ')]
    brandn = dfbrandì„¸íƒ.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandí’ˆì§ˆ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('í’ˆì§ˆ')]
    brando = dfbrandí’ˆì§ˆ.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandêµí™˜ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('êµí™˜')]
    brandp = dfbrandêµí™˜.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandì¬ì§ˆ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ì¬ì§ˆ')]
    brandq = dfbrandì¬ì§ˆ.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandê°€ê²© = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ê°€ê²©')]
    brandr = dfbrandê°€ê²©.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandëŠë‚Œ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ëŠë‚Œ')]
    brands = dfbrandëŠë‚Œ.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandëƒ„ìƒˆ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ëƒ„ìƒˆ')]
    brandt = dfbrandëƒ„ìƒˆ.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandë³´í’€ = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ë³´í’€')]
    brandu = dfbrandë³´í’€.shape[0] / dfbrandë¶€ì •.shape[0]

    dfbrandë§ˆê° = dfbrandë¶€ì •[dfbrandë¶€ì •['ë¦¬ë·°'].str.contains('ë§ˆê°')]
    brandv = dfbrandë§ˆê°.shape[0] / dfbrandë¶€ì •.shape[0]

    listbrandê¸ì •= [branda, brandb, brandc, brandd, brande, brandf, brandg, brandh, brandi, brandj, brandk]
    listbrandë¶€ì •= [brandl, brandm, brandn, brando, brandp, brandq, brandr, brands, brandt, brandu, brandv]

    Series3 = pd.Series(listbrandê¸ì •)
    Series4 = pd.Series(listbrandë¶€ì •)

    dfbrandê¸ì •ë¹„ìœ¨ = pd.DataFrame({"í‚¤ì›Œë“œ": Series1, "ë¹„ìœ¨": Series3})

    dfbrandë¶€ì •ë¹„ìœ¨ = pd.DataFrame({"í‚¤ì›Œë“œ": Series2, "ë¹„ìœ¨": Series4})

    # import matplotlib.pyplot as plt

    st.line_chart(wordê¸ì •, listê¸ì •, title='ê¸ì • í‚¤ì›Œë“œ ë¹„êµ')

    st.line_chart(wordê¸ì •, listbrandê¸ì •, title = 'ê¸ì • í‚¤ì›Œë“œ ë¹„êµ')

    st.imshow()

    st.line_chart(wordë¶€ì •, listë¶€ì •, title='ë¶€ì • í‚¤ì›Œë“œ ë¹„êµ')

    st.line_chart(wordë¶€ì •, listbrandë¶€ì •, title='ë¶€ì • í‚¤ì›Œë“œ ë¹„êµ')

    st.imshow()
  
try : 
    data_load_state = st.text('Loading data...') 
    data = data_load(select_brand[0])
    graph(data)
    pos_data = data[data["í‰ì "] == "100%"]
    neg_data = data[(data["í‰ì "] == "20%") | (data["í‰ì "] == "40%")]
except KeyError as k:
    pass
except IndexError as i:
    pass
except NameError as n:
    pass
# labeling
def labeling(data):
    df = data[["ë¦¬ë·°", "í‰ì "]]
    df = df.reset_index(drop=True)

    ì‚­ì œ = df[(df["í‰ì "]=="60%") | (df["í‰ì "]=="80%")].index
    df = df.drop(ì‚­ì œ)

    df.loc[(df["í‰ì "] == "100%"), "label"] = 1
    df.loc[(df["í‰ì "] == "20%") | (df["í‰ì "] == "40%"), "label"] = 0

    df = df.drop_duplicates()
    df = df.reset_index(drop=True)
    return df

# ë¬¸ì ì „ì²˜ë¦¬
def preprocessing(text):
    text = re.sub('[^ê°€-í£ã„±-ã…ã…-ã…£a-zA]', " ", text)
    text = re.sub('[\s]+', " ", text)
    text = text.lower()
    return text

try :
    label_data = labeling(data=data)
    positive = label_data[(label_data["í‰ì "] == "100%")].sample(10)
    negative = label_data[(label_data["í‰ì "] == "20%") | (label_data["í‰ì "] == "40%")].sample(10)
    positive['ë¦¬ë·°'] = positive['ë¦¬ë·°'].map(preprocessing)
    negative['ë¦¬ë·°'] = negative['ë¦¬ë·°'].map(preprocessing)
except KeyError as k:
    pass
except NameError as n:
    pass

# Kiwi ì ìš©
def noun_extractor(sentence):
    results = []
    result = Kiwi().analyze(sentence)
    for token, pos, _, _ in result[0][0]:
        if len(token) != 1 and pos.startswith('N') or pos.startswith('SL'):
            results.append(token)
    return results

try :
    pos_noun_list = []
    neg_noun_list = []
    print('ê¸ì • ë¦¬ë·° kiwi')
    for pos in positive['ë¦¬ë·°'].tolist():
        pos_nouns = noun_extractor(pos)
        pos_text = ' '.join(pos_nouns)
        pos_noun_list.append(pos_text)

    print('ë¶€ì • ë¦¬ë·° kiwi')
    for neg in negative['ë¦¬ë·°'].tolist():
        neg_nouns = noun_extractor(neg)
        neg_text = ' '.join(neg_nouns)
        neg_noun_list.append(neg_text)

except KeyError as k:
    pass
except NameError as n:
    pass

# wordrank ì ìš© top10 í‚¤ì›Œë“œ ë½‘ê¸°
def word_rank(corpus):
    beta = 0.90    # PageRankì˜ decaying factor beta
    max_iter = 5
    top_keywords = []
    fnames = [corpus]
    top_10=[]
    
    for fname in fnames:
        texts = fname
        wordrank_extractor = KRWordRank(min_count=1, max_length=10, verbose=False)
        keywords, rank, graph = wordrank_extractor.extract(texts, beta, max_iter)
        top_keywords.append(sorted(keywords.items(),key=lambda x:x[1],reverse=True)[:100])
        
    for i in range(len(top_keywords)):
        if i<10:
            top_10.append(top_keywords[0][i][0])
            i += 1
    return top_10

try :
    pos_keyword = word_rank(pos_noun_list)
    neg_keyword = word_rank(neg_noun_list)
except KeyError as k:
    pass
except NameError as n:
    pass
except ValueError as v:
    pass

# img data load
img_brand_link = {
    'ë¼í¼ì§€ìŠ¤í† ì–´' : '1QfwKjzDAfoowpe4LiH9yxhChdZo3iizh',
    'ë“œë¡œìš°í•' : '1-caqKnBlM4Q26tec_4aWFm9017F9-_E4',
    'ì»¤ë²„ë‚«' : '1f50QDJI6K7KeZ7WGSANV1sH6aiXa2c5T',
    'íŒŒë¥´í‹°ë©˜í† ' : '1Nt0LAAWlvVTh60Y9Zvbb3jmw0Jdl-URg',
    'í•„ë£¨ë¯¸ë„¤ì´íŠ¸' : '1CtYGt4E5hzqp-tvwix5WhANpvzds8TQK',
    'ê¼¼íŒŒë‡¨' : '1-CJcWAp3WxKymk7PUxj9NYgM-3zfjM83',
    'ì¸ì‚¬ì¼ëŸ°ìŠ¤' : '1COUpes3WPXeGn6mdYrtzG1D9dMJ43SF7' ,
    'ì™€ë¦¿ì´ì¦Œ' : '1nxOa5_69KQrmbMduDhQtAPFgiclIFXO_' ,
    'ìˆ˜ì•„ë ˆ' : '1G5QtrNYtKNhFgRVx0Fj2-b0F626o7ccX',
    'ë‚´ì…”ë„ì§€ì˜¤ê·¸ë˜í”½' : '1Wm2ox9koFbYXkMtvLApCfQjDnPfSRsGF',
    'ì˜ˆì¼' : '1MxqLCSCptl5O5shldxK513mh4G7z3j3V',    
    'ë””ì¦ˆì´ìŠ¤ë„¤ë²„ëŒ“' : '17yuM4U3W3aKKMCQphvBePiHC5mVugVkf',    
    'ì•„ì›ƒìŠ¤íƒ ë”©' : '17v-GwoTF0mgOkRta3hAhytWLPOh2YUpk',
    'ë¦¬' : '1us6tb40vHoz4hrNGfoD9n2BL0fciY97n',
    'ì–´ë°˜ë“œë ˆìŠ¤' : '1LDAyqzM-TZZCLVrZJK08WLJe2IF6Jtxt' 
}

def img_data_load(select_brand):
    for brand in select_brand:
        img_data_link = f'https://drive.google.com/uc?id='+img_brand_link[brand]
        img_csv = pd.read_csv(img_data_link) 
    return img_csv  


def keyword_review(img_link, df, keywords):
    # ê° í‚¤ì›Œë“œ forë¬¸ìœ¼ë¡œ ëŒë¦¬ê¸°
    for key_count in range(len(keywords)):
        # í‚¤ì›Œë“œì˜ ë‹¨ì–´ë¥¼ í¬í•¨í•˜ëŠ” ë¦¬ë·°ë¥¼ keyword_review_dataë¡œ í• ë‹¹
        keyword_review_data = df[df['ë¦¬ë·°'].str.contains(keywords[key_count])]

        # ê·¸ í• ë‹¹í•œ ë³€ìˆ˜ì—ì„œ ìƒí’ˆ ë²ˆí˜¸ë¥¼ ê°€ì ¸ì˜¤ê³ , ê°€ì¥ ë§ì´ ì°¨ì§€í•˜ëŠ” top3ì˜ ìƒí’ˆ ë²ˆí˜¸ë¥¼ ê°€ì ¸ì˜¤ê¸°
        product_num = keyword_review_data['ìƒí’ˆ_num']
        top3_cumc_product = product_num.value_counts().sort_values(ascending=False)[:3].index

        # top3ì˜ ìƒí’ˆ ë²ˆí˜¸ì— í•´ë‹¹í•˜ëŠ” ë¦¬ë·° ê°ê° 3ê°œì˜ ë¦¬ë·° ê°€ì ¸ì˜¤ê¸°
        review1 = keyword_review_data[keyword_review_data['ìƒí’ˆ_num']==top3_cumc_product[0]]['ë¦¬ë·°'].sample(3)
        review2 = keyword_review_data[keyword_review_data['ìƒí’ˆ_num']==top3_cumc_product[1]]['ë¦¬ë·°'].sample(3)
        review3 = keyword_review_data[keyword_review_data['ìƒí’ˆ_num']==top3_cumc_product[2]]['ë¦¬ë·°'].sample(3)

        st.button(keywords[key_count])
        
        for i, number in enumerate(top3_cumc_product):
            # ìƒí’ˆëª…
            product_name_list = keyword_review_data[keyword_review_data['ìƒí’ˆ_num'] == top3_cumc_product[i]]['ìƒí’ˆ']
            product_name = list(set(product_name_list))
            st.text(f'ìƒí’ˆ ì˜µì…˜ : {product_name}')

            # ì´ë¯¸ì§€ ë§í¬
            #imgs_link = img_link[img_link['ìƒí’ˆ_num'] == number]['ì‚¬ì§„'].values
            #join_link = ''.join(imgs_link)
            #link = f'https:{join_link}'
            #st.text(f'ì´ë¯¸ì§€ ë§í¬ : {link}')
            
            #image = Image.open(f'{img_link}')
            #st.image(image)

            if i==0:
                st.text(review1.values)
            if i==1:
                st.text(review2.values)
            if i==2:
                st.text(review3.values)

#            link = img_link[img_link['ìƒí’ˆ_num'] == num]['ì‚¬ì§„'].values
#            join_link = ''.join(link)
#            URL = f'https:{join_link}'
#            response = requests.get(URL)
#            image = Image.open(BytesIO(response.content))
#            st.image(image, caption='Image from URL')
        

try :
    link_csv = img_data_load(select_brand)
    st.markdown("""## ğŸ™‚ ê¸ì • ë¦¬ë·° í•µì‹¬ í‚¤ì›Œë“œ""")
    pos = keyword_review(link_csv, pos_data, pos_keyword)
    st.text(pos)
    st.markdown("""## ğŸ™ ë¶€ì • ë¦¬ë·° í•µì‹¬ í‚¤ì›Œë“œ""")
    neg = keyword_review(link_csv, neg_data, neg_keyword)
    st.text(neg)
except KeyError as k:
    pass
except IndexError as i:
    pass
except NameError as n:
    pass


